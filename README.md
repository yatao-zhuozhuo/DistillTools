# Day4 Exercise: 长思考和搜索工具调用训练

本项目使用 DeepSeek-R1-Distill-Qwen-7B 合成训练数据，并基于 Qwen2.5-0.5B-Instruct 进行 LoRA 微调，训练具有长思考和网络搜索工具调用能力的模型。

## 1. 数据合成
使用 DeepSeek-R1-Distill-Qwen-7B 生成训练数据，数据生成流程：

1. 从两类问题文件（需要思考的问题和需要搜索的问题）中加载问题集
2. 分阶段生成内容：先分析问题，再生成最终答案
3. 结构化输出：使用特殊标签(<thinking>, <tool_call>)标记不同部分，这样的原因是7B模型能力不足，很难准确的自己添加标签，因此采用这种硬编码的方式添加进去

输出格式：
```json
{
    "messages": [
        {"role": "user", "content": "问题"},
        {"role": "assistant", "content": "<thinking>推理过程</thinking>"}
    ],
    "type": "thinking"
}
```

## 2. LoRA 训练
基于 Qwen2.5-0.5B-Instruct 使用合成的数据进行训练：

LoRA 微调参数配置表

| 参数                      | 值/选项                |
|---------------------------|-----------------------|
| `r`                       | 16                    |
| `lora_alpha`              | 32                    |
| `batch_size`              | 2                     |
| `gradient_accumulation`   | 8                     |
| `learning_rate`           | 2e-4                  |

## 3. 模型推理

经过 LoRA 微调的模型现在应该具备两项能力：**长思考**和**搜索工具调用**。推理设计的核心思路是让模型能够智能地判断问题类型，并采用相应的处理策略。

### 系统 Prompt 设计

为了让模型理解何时使用这些能力，设计了引导性的系统提示：

```
你是一个智能助手，具有以下能力：
1. 对复杂问题进行深入思考，使用<thinking>标签包围你的思考过程
2. 判断是否需要调用网络搜索工具来获取最新信息
3. 处理网络搜索结果并进行分析

当遇到需要最新信息、实时数据或你不确定的事实时，你应该调用search工具。
格式如下：
<tool_call>
{"name": "search", "arguments": {"query": "搜索关键词"}}
</tool_call>

在回答之前，请在<thinking>标签中进行思考。
```

### 交互示例

**场景1：需要深度思考的数学问题**
```
用户：如果一个正方形的面积是另一个正方形面积的4倍，那么它们的周长比是多少？

助手：<thinking>
这是一个几何问题，需要运用面积和周长的关系。
设小正方形的边长为a，大正方形的边长为b。
已知：b² = 4a²，所以b = 2a
小正方形周长 = 4a，大正方形周长 = 4b = 8a
周长比 = 8a : 4a = 2 : 1
</thinking>

根据面积关系可以推导出边长关系，进而得到周长比。如果大正方形面积是小正方形的4倍，那么大正方形的边长是小正方形的2倍，因此周长比是2:1。
```

**场景2：需要搜索的实时信息**
```
用户：今天比特币的价格是多少？

助手：<thinking>
这个问题需要最新的实时数据，我需要搜索当前的比特币价格信息。
</thinking>

<tool_call>
{"name": "search", "arguments": {"query": "比特币价格 今日"}}
</tool_call>

[搜索结果]: 关于'比特币价格 今日'的搜索结果...

根据最新的搜索结果，比特币当前价格约为...[基于搜索结果提供具体信息]
```


## 4. 模型评测
### 评测指标
采用标签命中率作为核心评测指标，评估模型在不同任务类型上的表现：  
思考类任务：评测模型是否能正确输出 <thinking> 标签并包含推理过程  
搜索类任务：评测模型是否能正确输出 <function_calls> 标签并调用搜索工具

### 评测流程
评测基于合成的测试数据集，测试流程如下：  
数据准备：从 synthetic_data.json 中加载测试样本，这个数据是模仿之前的数据由gpt合成  
模型推理：使用微调后的模型对每个样本进行推理生成  
标签检测：检查模型输出中是否包含期望的特殊标签  
统计计算：计算各类任务的命中率和整体表现  

### 评测结果
| 测试类别       | 样本总数 | 标签命中数 | 命中率   | 备注                          |
|----------------|----------|------------|----------|-------------------------------|
| **思考类样本** | 30       | 30         | 100.00%  | 全部正确生成 `<thinking>` 标签 |
| **搜索类样本** | 30       | 22         | 73.33%   | 部分未触发工具调用逻辑         |

## 5.  文件结构

```
day4-exercise/
├── data_synthesis.py          # 数据合成代码
├── train_lora.py             # LoRA训练代码
├── inference.py              # 模型推理代码
├── requirements.txt          # 依赖包列表
├── setup_env.sh             # 环境安装脚本
├── run_data_synthesis.sh    # 数据合成运行脚本
├── run_training.sh          # 训练运行脚本
├── run_inference.sh         # 推理运行脚本
├── README.md                # 使用说明
├── synthetic_data.json      # 合成的训练数据（运行后生成）
└── qwen_lora_model/         # 训练完成的模型（训练后生成）
```

项目链接见 https://github.com/yatao-zhuozhuo/DistillTools
